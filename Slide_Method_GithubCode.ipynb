{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HG7jsefa7Ytv",
        "q2-mqQHxjbp7",
        "LKtNtcAvWYHR",
        "NsO4J-H-x91p",
        "kx6ifdU4x5rc"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swfzlsIOjG57",
        "outputId": "c3aa006a-d1e6-4a57-9160-282ac5cf31b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeTCajbg-Dfp"
      },
      "source": [
        "## install package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "e6360311-faf1-43ef-a6dd-f0e9f1024e18",
        "id": "6_SE92PD-Dfp"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.14.1-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading SpeechRecognition-3.14.1-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.14.1 pydub-0.25.1\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Collecting deepgram-sdk\n",
            "  Downloading deepgram_sdk-3.9.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from deepgram-sdk) (0.28.1)\n",
            "Requirement already satisfied: websockets>=12.0 in /usr/local/lib/python3.11/dist-packages (from deepgram-sdk) (14.2)\n",
            "Collecting dataclasses-json>=0.6.3 (from deepgram-sdk)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from deepgram-sdk) (4.12.2)\n",
            "Requirement already satisfied: aiohttp>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from deepgram-sdk) (3.11.11)\n",
            "Collecting aiofiles>=23.2.1 (from deepgram-sdk)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting aenum>=3.1.0 (from deepgram-sdk)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting deprecation>=2.1.0 (from deepgram-sdk)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9.1->deepgram-sdk) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9.1->deepgram-sdk) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9.1->deepgram-sdk) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9.1->deepgram-sdk) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9.1->deepgram-sdk) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9.1->deepgram-sdk) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9.1->deepgram-sdk) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json>=0.6.3->deepgram-sdk)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json>=0.6.3->deepgram-sdk)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from deprecation>=2.1.0->deepgram-sdk) (24.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->deepgram-sdk) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->deepgram-sdk) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->deepgram-sdk) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->deepgram-sdk) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->deepgram-sdk) (0.14.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.6.3->deepgram-sdk)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->deepgram-sdk) (1.3.1)\n",
            "Downloading deepgram_sdk-3.9.0-py3-none-any.whl (148 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.9/148.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: aenum, mypy-extensions, marshmallow, deprecation, aiofiles, typing-inspect, dataclasses-json, deepgram-sdk\n",
            "Successfully installed aenum-3.1.15 aiofiles-24.1.0 dataclasses-json-0.6.7 deepgram-sdk-3.9.0 deprecation-2.1.0 marshmallow-3.26.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.36.1)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.12.14)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.11/dist-packages (3.14.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2024.12.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m769.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.59.9\n",
            "    Uninstalling openai-1.59.9:\n",
            "      Successfully uninstalled openai-1.59.9\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub SpeechRecognition\n",
        "!pip install requests\n",
        "!pip install deepgram-sdk\n",
        "\n",
        "!pip install pydub moviepy librosa\n",
        "!pip install SpeechRecognition\n",
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3baaf345-d808-4dc7-bdf2-60ea0f70aa9b",
        "id": "X7cMFpi0-Dfp"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import speech_recognition as sr\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip, ImageClip, concatenate_videoclips\n",
        "from pydub import AudioSegment, effects\n",
        "from pydub import silence\n",
        "from pydub.silence import split_on_silence\n",
        "from pydub.silence import detect_silence\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import os\n",
        "import re\n",
        "import cv2\n",
        "\n",
        "import json\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "import textwrap\n",
        "from deepgram import DeepgramClient, PrerecordedOptions, FileSource\n",
        "\n",
        "import openai\n",
        "from skimage.metrics import structural_similarity as ssim\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function"
      ],
      "metadata": {
        "id": "_kzZerUh-Dfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Video Frame Recognition"
      ],
      "metadata": {
        "id": "W7ECxxK0-Dfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_slide_changes(video_path, slides_detect_threshold):\n",
        "\n",
        "    THRESHOLD = slides_detect_threshold\n",
        "\n",
        "    clip = VideoFileClip(video_path)\n",
        "    fps = clip.fps\n",
        "    total_time = clip.duration\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    previous_frame = None\n",
        "    original_timestamps = []\n",
        "    original_timestamps.append(0)\n",
        "    slide_pictures = []\n",
        "\n",
        "\n",
        "    first_second_found = False\n",
        "\n",
        "    frame_count = 0\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        if not first_second_found and frame_count / fps < 1:\n",
        "            resized_frame = cv2.resize(frame, (video_width, video_height))\n",
        "            slide_pictures.append(cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB))\n",
        "            first_second_found = True\n",
        "\n",
        "        if previous_frame is not None:\n",
        "            diff = cv2.absdiff(previous_frame, gray_frame)\n",
        "            difference = np.mean(diff)\n",
        "\n",
        "            if difference > THRESHOLD:\n",
        "                time_position = frame_count / fps\n",
        "                original_timestamps.append(time_position)\n",
        "\n",
        "                resized_frame = cv2.resize(frame, (video_width, video_height))\n",
        "                slide_pictures.append(cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "        previous_frame = gray_frame\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    original_timestamps.append(total_time)\n",
        "\n",
        "    return original_timestamps, slide_pictures"
      ],
      "metadata": {
        "id": "ksCL1JQb-Dfq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_repeat_pictures(detect_slide_pictures, original_timestamps):\n",
        "    results = []\n",
        "    delete_index = []\n",
        "\n",
        "    for i in range(len(detect_slide_pictures) - 1):\n",
        "        ssim_score = compute_ssim(detect_slide_pictures[i], detect_slide_pictures[i + 1])\n",
        "\n",
        "        if ssim_score > 0.99:\n",
        "            delete_index.append(i + 1)\n",
        "\n",
        "    delete_index = sorted(set(delete_index), reverse=True)\n",
        "    for index in delete_index:\n",
        "        del detect_slide_pictures[index]\n",
        "        del original_timestamps[index]\n",
        "\n",
        "    return detect_slide_pictures, original_timestamps"
      ],
      "metadata": {
        "id": "fn0NkIIz-Dfq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Time_group(original_timestamps, slide_pictures):\n",
        "    time_group = {}\n",
        "    index = 0\n",
        "    time_group[index] = [(original_timestamps[0], slide_pictures[0])]\n",
        "\n",
        "    for i in range(1, len(original_timestamps)-1):\n",
        "        if original_timestamps[i] - original_timestamps[i - 1] < 2:\n",
        "          time_group[index].append((original_timestamps[i], slide_pictures[i]))\n",
        "        else:\n",
        "          index += 1\n",
        "          time_group[index] = [(original_timestamps[i], slide_pictures[i])]\n",
        "\n",
        "    return time_group"
      ],
      "metadata": {
        "id": "ahNhV_qV-Dfq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_ssim(img1, img2, threshold = 0.9):\n",
        "    gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
        "    gray2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
        "    score, _ = ssim(gray1, gray2, full=True)\n",
        "    return score\n",
        "\n",
        "def SSIM_group(time_group, ssim_threshold):\n",
        "\n",
        "    ssim_group = {}\n",
        "    new_index = 0\n",
        "\n",
        "    for key, images in time_group.items():\n",
        "        timestamps = [ts for ts, _ in images]\n",
        "        image_arrays = [img for _, img in images]\n",
        "        split_indices = []\n",
        "\n",
        "        for i in range(len(image_arrays) - 1):\n",
        "            ssim_score = compute_ssim(image_arrays[i], image_arrays[i + 1])\n",
        "\n",
        "            if ssim_score < ssim_threshold:\n",
        "                split_indices.append(i + 1)\n",
        "\n",
        "        if not split_indices:\n",
        "            ssim_group[new_index] = images\n",
        "            new_index += 1\n",
        "        else:\n",
        "\n",
        "            start = 0\n",
        "            for split_index in split_indices:\n",
        "                ssim_group[new_index] = images[start:split_index]\n",
        "                new_index += 1\n",
        "                start = split_index\n",
        "\n",
        "            if start < len(images):\n",
        "                ssim_group[new_index] = images[start:]\n",
        "                new_index += 1\n",
        "    return ssim_group"
      ],
      "metadata": {
        "id": "OIl4w_LD-Dfq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def silent_segment(ssim_group):\n",
        "    silent_segments = {}\n",
        "    original_text_timestamps = []\n",
        "    slide_pictures = []\n",
        "    index = 0\n",
        "\n",
        "    for index in range(len(ssim_group) - 1):\n",
        "        current_group = ssim_group[index]\n",
        "        next_group = ssim_group[index + 1]\n",
        "\n",
        "        duration = next_group[0][0] - current_group[0][0]\n",
        "\n",
        "        if duration <= 2:\n",
        "\n",
        "            if index - 1 in silent_segments:\n",
        "                silent_segments[index - 1][1] = next_group[0][0]\n",
        "            else:\n",
        "                silent_segments[index - 1] = [current_group[0][0], next_group[0][0]]\n",
        "        else:\n",
        "            original_text_timestamps.append(current_group[0][0])\n",
        "            slide_pictures.append(current_group[-1][1])\n",
        "\n",
        "    last_key = max(ssim_group.keys())\n",
        "    last_group = ssim_group[last_key]\n",
        "\n",
        "    if len(ssim_group) < 2 or (last_group[0][0] - ssim_group[last_key - 1][0][0]) > 2:\n",
        "        original_text_timestamps.append(last_group[0][0])\n",
        "        slide_pictures.append(last_group[-1][1])\n",
        "\n",
        "    if original_timestamps[-1] not in original_text_timestamps:\n",
        "        original_text_timestamps.append(original_timestamps[-1])\n",
        "\n",
        "    return silent_segments, original_text_timestamps, slide_pictures\n"
      ],
      "metadata": {
        "id": "WVjw4cni-Dfq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Audio Segmentation"
      ],
      "metadata": {
        "id": "8smm7VTB-Dfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_audio_segments(video_path, timestamps, audioSegmentation):\n",
        "\n",
        "    audio_files = []\n",
        "    durations = []\n",
        "\n",
        "    video_clip = VideoFileClip(video_path)\n",
        "\n",
        "    for i in range(len(timestamps) - 1):\n",
        "        start_time = timestamps[i]\n",
        "        end_time = timestamps[i + 1]\n",
        "\n",
        "        audio_segment = video_clip.audio.subclip(start_time, end_time)\n",
        "        output_file = f\"{audioSegmentation}/original_audio_segment_{i}.wav\"\n",
        "\n",
        "        audio_segment.write_audiofile(output_file, codec='pcm_s16le')\n",
        "        audio_files.append(output_file)\n",
        "\n",
        "        durations.append(audio_segment.duration)\n",
        "\n",
        "    video_clip.close()\n",
        "\n",
        "    return audio_files, durations\n",
        ""
      ],
      "metadata": {
        "id": "v7_UrNtT-Dfq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. ASR"
      ],
      "metadata": {
        "id": "9ARDFNUs-Dfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def videos_to_texts(audio_files):\n",
        "\n",
        "    try:\n",
        "        deepgram = DeepgramClient(f\"{deepgrame_key}\")\n",
        "        results = []\n",
        "\n",
        "        for audio_file in audio_files:\n",
        "            with open(audio_file, \"rb\") as file:\n",
        "                response = deepgram.listen.rest.v(\"1\").transcribe_file({\"buffer\": file.read()}, {\"model\": \"nova-2\", \"smart_format\": True})\n",
        "\n",
        "            text = \"\"\n",
        "            for channel in json.loads(response.to_json())['results']['channels']:\n",
        "                text += \" \".join([s['text'] for p in channel['alternatives'][0]['paragraphs']['paragraphs'] for s in p['sentences']]) + \" \"\n",
        "\n",
        "            word_count = len(text.split())\n",
        "\n",
        "            audio_clip = AudioFileClip(audio_file)\n",
        "            duration = audio_clip.duration\n",
        "            audio_clip.close()\n",
        "\n",
        "            results.append((text, duration, word_count))\n",
        "\n",
        "        original_text_segments = [text for text, duration, word_count in results]\n",
        "\n",
        "        return original_text_segments\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Exception occurred: {str(e)}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "LANDrpUf-Dfr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. LLM"
      ],
      "metadata": {
        "id": "4peW29Le-Dfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LLM_modify_text(original_text_segments):\n",
        "\n",
        "    original_text_dict = {index: value for index, value in enumerate(original_text_segments)}\n",
        "\n",
        "    prompt = (f'''\n",
        "    Please modify the following transcript which comes from a transcript as a whole, with attention to the following requirements:\n",
        "    1. Correct any grammatical mistakes and mispronunciations;\n",
        "    2. Keep the total number of segments unchanged;\n",
        "    3. Ensure that the word count per segment remains approximately the same;\n",
        "    4. Make as few alterations as necessary;\n",
        "    5. The content of the revised segments should exactly resemble that of the original;\n",
        "    6. Format the output as a python dictionary, with double quotes (\") instead of single quotes (') for keys and values.\n",
        "\n",
        "    Transcript:\n",
        "    {original_text_dict}\n",
        "    ''')\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    revised_transcript = response['choices'][0]['message']['content']\n",
        "\n",
        "    parsed_data = json.loads(revised_transcript)\n",
        "    polished_text_segments = list(parsed_data.values())\n",
        "\n",
        "    return polished_text_segments\n"
      ],
      "metadata": {
        "id": "3QE7gpVp-Dfr"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Voice Clone"
      ],
      "metadata": {
        "id": "s8XFQqsa-Dfr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "hBI13mxj-Dfr"
      },
      "outputs": [],
      "source": [
        "def voice_clone(input_video):\n",
        "\n",
        "    url = \"https://api.play.ht/api/v2/cloned-voices/instant\"\n",
        "\n",
        "    files = { \"sample_file\": (f\"{input_video}\", open(f\"{input_video}\", \"rb\"), \"audio/mpeg\") }\n",
        "    # The audio file selected as the source for the voice clone should have a duration ranging from 2 seconds to 1 hour.\n",
        "    # It can be in any audio format,\n",
        "    # as long as it falls within the size range of 5kb to 50MB.\n",
        "    payload = { \"voice_name\": \"Cloned_Voice\" }\n",
        "    headers = {\n",
        "        \"accept\": \"application/json\",\n",
        "        \"AUTHORIZATION\": f\"{playht_key}\",\n",
        "        \"X-USER-ID\": f\"{playht_id}\"\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, data=payload, files=files, headers=headers)\n",
        "\n",
        "    response_dict = json.loads(response.text)\n",
        "    voiceID = response_dict['id']\n",
        "\n",
        "    return voiceID"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. TTS"
      ],
      "metadata": {
        "id": "YHXz2B1N-Dfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def text_to_url(polish_sentence, speed, voiceID, UserID, UserKey):\n",
        "\n",
        "    if not polish_sentence.strip():\n",
        "        return None\n",
        "\n",
        "    sentence = polish_sentence\n",
        "    url = \"https://api.play.ht/api/v2/tts\"\n",
        "    headers = {\n",
        "        \"accept\": \"text/event-stream\",\n",
        "        \"content-type\": \"application/json\",\n",
        "        \"AUTHORIZATION\": UserKey,\n",
        "        \"X-USER-ID\": UserID\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "        \"text\": sentence,\n",
        "        \"voice\": voiceID,\n",
        "        \"output_format\": \"wav\",\n",
        "        \"voice_engine\": \"PlayHT2.0\",\n",
        "        \"temperature\": 0.1,\n",
        "        \"seed\": 1,\n",
        "        \"speed\": speed,\n",
        "        \"voice_guidance\": 1,\n",
        "        \"style_guidance\": 1,\n",
        "        \"sample_rate\": 24000\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "    for line in response.text.splitlines():\n",
        "        if line.startswith('data: '):\n",
        "            data = line[len('data: '):]\n",
        "            try:\n",
        "                json_data = json.loads(data)\n",
        "                if json_data.get('stage') == 'complete':\n",
        "                    URL = json_data.get('url')\n",
        "\n",
        "\n",
        "            except json.JSONDecodeError:\n",
        "                continue\n",
        "    return URL"
      ],
      "metadata": {
        "id": "pRF6Q2fi-Dfr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def blocks_to_urls(polish_blocks, voiceID, UserID, UserKey, speed):\n",
        "\n",
        "    URLs = []\n",
        "    for block in polish_blocks:\n",
        "        URL = text_to_url(block, speed, voiceID, UserID, UserKey)\n",
        "        URLs.append(URL)\n",
        "\n",
        "    return URLs"
      ],
      "metadata": {
        "id": "iiJVt3Zp-Dfr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Align Video and Audio"
      ],
      "metadata": {
        "id": "Hnt2h2Ty-Dfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_audio_segments(urls, original_audio_durations, silent_segments):\n",
        "    final_audio_fixed = AudioSegment.empty()\n",
        "    audio_durations = []\n",
        "\n",
        "    for key, (start_time, end_time) in silent_segments.items():\n",
        "        if key < 1:\n",
        "            time_diff = abs(end_time - start_time)\n",
        "            if time_diff <= 2:\n",
        "                time_diff = time_diff + 1\n",
        "\n",
        "            silence_duration = time_diff * 1000\n",
        "            silence_audio = AudioSegment.silent(duration=silence_duration)\n",
        "            final_audio_fixed += silence_audio\n",
        "\n",
        "    for index, url in enumerate(urls):\n",
        "\n",
        "        final_audio_fixed += AudioSegment.silent(duration=1000)\n",
        "        if url is None:\n",
        "\n",
        "            silence_duration = original_audio_durations[index] * 1000\n",
        "            silence_audio = AudioSegment.silent(duration=silence_duration)\n",
        "            final_audio_fixed += silence_audio\n",
        "            audio_durations.append(silence_duration / 1000)\n",
        "        else:\n",
        "            response = requests.get(url)\n",
        "            audio = AudioSegment.from_file(BytesIO(response.content), format=\"wav\")\n",
        "\n",
        "            audio_duration = audio.duration_seconds\n",
        "            audio_durations.append(audio_duration)\n",
        "\n",
        "            final_audio_fixed += audio\n",
        "\n",
        "            if index == len(urls) - 1:\n",
        "                final_audio_fixed += AudioSegment.silent(duration=1000)\n",
        "\n",
        "        i = index\n",
        "        if i in silent_segments:\n",
        "            start_time, end_time = silent_segments[i]\n",
        "            time_diff = abs(end_time - start_time)\n",
        "\n",
        "            if time_diff <= 2:\n",
        "              time_diff = time_diff + 1\n",
        "\n",
        "            silence_duration = time_diff * 1000\n",
        "            silence_audio = AudioSegment.silent(duration=silence_duration)\n",
        "            final_audio_fixed += silence_audio\n",
        "\n",
        "    modified_audio = final_audio_fixed\n",
        "    total_duration = modified_audio.duration_seconds\n",
        "\n",
        "    for idx, audio_length in enumerate(audio_durations):\n",
        "        print(f\"Duration of audio {idx + 1} is {audio_length} seconds\")\n",
        "\n",
        "    print(f\"Total duration of the concatenated audio is {total_duration} seconds\")\n",
        "\n",
        "    return modified_audio, total_duration, audio_durations\n"
      ],
      "metadata": {
        "id": "8-Z6cHw1-Dfs"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_video_segments(video_path, original_timestamps, final_audio_durations, slide_pictures, silent_segments):\n",
        "\n",
        "    video = VideoFileClip(video_path)\n",
        "    original_video_segments = [video.subclip(original_timestamps[i], int(original_timestamps[i + 1])) for i in range(len(original_timestamps) - 1)]\n",
        "    final_audio_durations = [duration + 1 for duration in final_audio_durations]\n",
        "\n",
        "    polished_video_segments = []\n",
        "    for key, (start_time, end_time) in silent_segments.items():\n",
        "        if key < 1:\n",
        "            time_diff = abs(end_time - start_time)\n",
        "            if time_diff <= 2:\n",
        "                end_time = end_time - 1\n",
        "            silent_video_segment = video.subclip(start_time, end_time).without_audio()\n",
        "            polished_video_segments.append(silent_video_segment)\n",
        "\n",
        "    for i, video_segment in enumerate(original_video_segments):\n",
        "        original_duration = video_segment.duration\n",
        "\n",
        "        if i == len(original_video_segments) - 1:\n",
        "            target_duration = final_audio_durations[i] + 1\n",
        "        else:\n",
        "            target_duration = final_audio_durations[i]\n",
        "\n",
        "        if original_duration > target_duration:\n",
        "            trimmed_segment = video_segment.subclip(0, target_duration).without_audio()\n",
        "            polished_segment = trimmed_segment\n",
        "        else:\n",
        "            slide_image = slide_pictures[i]\n",
        "            slide_image_bgr = cv2.cvtColor(slide_image, cv2.COLOR_RGB2BGR)\n",
        "            slide_clip = ImageClip(slide_image).set_duration(target_duration - original_duration)\n",
        "            slide_clip = slide_clip.resize(height=video_segment.h)\n",
        "            extended_segment = concatenate_videoclips([video_segment, slide_clip])\n",
        "            polished_segment = extended_segment\n",
        "\n",
        "        if i in silent_segments:\n",
        "            start_time, end_time = silent_segments[i]\n",
        "            time_diff = abs(end_time - start_time)\n",
        "\n",
        "            if time_diff <= 2:\n",
        "                start_time = max(0, start_time - 1)  # Ensure start_time doesn't go negative\n",
        "\n",
        "            silent_video_segment = video.subclip(start_time, end_time).without_audio()\n",
        "            extended_silent_segment = concatenate_videoclips([polished_segment, silent_video_segment])\n",
        "        else:\n",
        "            extended_silent_segment = polished_segment\n",
        "\n",
        "        polished_video_segments.append(extended_silent_segment)\n",
        "\n",
        "    return polished_video_segments"
      ],
      "metadata": {
        "id": "ctHxjEpm-Dfs"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_final_video(polished_video_segments, final_audio, final_video_path, audioSegmentation):\n",
        "\n",
        "    final_video = concatenate_videoclips(polished_video_segments)\n",
        "    temp_audio_file = f\"{directory_path}/temporary/final_audio.wav\"\n",
        "    final_audio.export(temp_audio_file, format=\"wav\")\n",
        "\n",
        "    final_audio_clip = AudioFileClip(temp_audio_file)\n",
        "    final_video = final_video.set_audio(final_audio_clip)\n",
        "    final_video.write_videofile(final_video_path, codec=\"libx264\", audio_codec=\"aac\", fps=24)\n",
        "\n",
        "    os.remove(temp_audio_file)\n",
        "\n",
        "    print(\"Final video saved successfully!\")"
      ],
      "metadata": {
        "id": "CrbOegmy-Dfs"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input information"
      ],
      "metadata": {
        "id": "foYlkGaB-Dfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "playht_key = 'put your api information here'\n",
        "playht_id = 'put your api information here'\n",
        "\n",
        "deepgrame_key = 'put your api information here'\n",
        "openai.api_key = 'put your api information here'\n",
        "directory_path = 'temporal file will be save here when running the code'\n",
        "input_video = 'input video path'\n",
        "output_video = 'output video path'"
      ],
      "metadata": {
        "id": "xs6lKTZB-Dfs"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running code"
      ],
      "metadata": {
        "id": "gmQny9BI-Dfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "speed = 0.85\n",
        "slides_detect_threshold = 0.2\n",
        "ssim_threshold = 0.9\n",
        "\n",
        "# 1. Video Frame Recognition\n",
        "original_timestamps, detect_slide_pictures = extract_slide_changes(input_video, slides_detect_threshold)\n",
        "detect_slide_pictures, original_timestamps = delete_repeat_pictures(detect_slide_pictures, original_timestamps)\n",
        "time_group = Time_group(original_timestamps, detect_slide_pictures)\n",
        "ssim_group = SSIM_group(time_group, ssim_threshold)\n",
        "silent_segments, original_text_timestamps, final_slide_pictures = silent_segment(ssim_group)\n",
        "\n",
        "# 2. Audio Segmentation\n",
        "original_audio_segments, original_audio_durations = extract_audio_segments(input_video, original_text_timestamps, directory_path)\n",
        "\n",
        "# 3. ASR\n",
        "original_text_segments = videos_to_texts(original_audio_segments)\n",
        "\n",
        "# 4. LLM\n",
        "polished_text_segments = LLM_modify_text(original_text_segments)\n",
        "\n",
        "# 5. Voice Clone\n",
        "voiceID = voice_clone(input_video)\n",
        "\n",
        "# 6. TTS\n",
        "URLs = blocks_to_urls(polished_text_segments, voiceID, playht_id, playht_key, speed)\n",
        "\n",
        "# 7. Align Video and Audio\n",
        "final_audio, final_total_duration, final_audio_durations = process_audio_segments(URLs, original_audio_durations, silent_segments)\n",
        "polished_video_segments = process_video_segments(input_video, original_text_timestamps, final_audio_durations, final_slide_pictures, silent_segments)\n",
        "save_final_video(polished_video_segments, final_audio, output_video, directory_path)"
      ],
      "metadata": {
        "id": "l2_RCylv-Dfs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}